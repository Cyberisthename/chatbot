# ğŸš€ Jarvis Quantum LLM - Quick Start Guide

**Get up and running with Jarvis in Ollama in 5 minutes!**

---

## âš¡ Super Quick Start (One Command)

```bash
chmod +x setup.sh
./setup.sh
```

That's it! The script will:
1. Check prerequisites
2. Install dependencies
3. Convert model to GGUF
4. Create Ollama model
5. Run tests

---

## ğŸ“ Manual Setup (Step by Step)

### 1. Install Ollama

**Linux/Mac:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows:**
Download from https://ollama.ai/download

### 2. Install Python Dependencies

```bash
pip install numpy requests
```

### 3. Convert Model

```bash
python3 numpy_to_gguf.py
```

This creates `jarvis-quantum.gguf` from the trained NumPy weights.

### 4. Create Ollama Model

```bash
ollama create jarvis -f Modelfile
```

### 5. Run Jarvis!

```bash
ollama run jarvis
```

---

## ğŸ’¬ Example Conversation

```
>>> What is quantum mechanics?

Quantum mechanics is the fundamental principles of quantum mechanics and 
wave-particle duality. This research explores the fundamental principles of 
quantum mechanics through advanced theoretical frameworks and experimental 
observations. The study demonstrates that quantum mechanics plays a critical 
role in our understanding of nature...

>>> Explain neural networks

Neural networks are computational architectures inspired by biological neural 
systems. They consist of interconnected layers that process information through 
backpropagation and gradient descent. The quantum-inspired approach integrates 
these networks with advanced statistical analysis...

>>> exit
```

---

## ğŸ”§ Common Commands

### List Models
```bash
ollama list
```

### Remove Model
```bash
ollama rm jarvis
```

### Recreate Model (after changes)
```bash
ollama rm jarvis
ollama create jarvis -f Modelfile
```

### Run with Custom Parameters
```bash
ollama run jarvis --temperature 0.9 --top-p 0.95
```

---

## ğŸ§ª Testing

### Automated Tests
```bash
python3 test_ollama.py
```

### Interactive Testing
```bash
python3 test_ollama.py interactive
```

---

## ğŸ¯ Different Quantization Levels

Want to try different size/speed tradeoffs?

### Q4_0 (Smallest, Fastest)
```bash
python3 quantize_model.py --quant q4_0
# Update Modelfile: FROM ./jarvis-quantum-q4_0.gguf
ollama create jarvis -f Modelfile
```

### Q8_0 (Balanced - Default)
```bash
python3 quantize_model.py --quant q8_0
# Already the default!
```

### F16 (High Quality)
```bash
python3 quantize_model.py --quant f16
# Update Modelfile: FROM ./jarvis-quantum-f16.gguf
ollama create jarvis -f Modelfile
```

---

## ğŸ“š More Training Data

Want better results? Generate more training data:

```bash
python3 enhanced_training.py
```

This creates 3000+ additional scientific documents. Then:

1. Copy enhanced data to parent directory training folder
2. Retrain the model with the new data
3. Convert to GGUF again
4. Recreate Ollama model

---

## ğŸŒ API Usage

### Start Ollama Server
```bash
ollama serve
```

### Python Example
```python
import requests

response = requests.post('http://localhost:11434/api/generate', json={
    'model': 'jarvis',
    'prompt': 'Explain quantum entanglement',
    'stream': False
})

print(response.json()['response'])
```

### cURL Example
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "jarvis",
  "prompt": "What is backpropagation?"
}'
```

---

## ğŸ› Troubleshooting

### "Model not found"
```bash
# Check if model exists
ollama list

# If not, create it
ollama create jarvis -f Modelfile
```

### "Connection refused"
```bash
# Start Ollama server
ollama serve
```

### "Conversion failed"
```bash
# Check source files
ls -lh ../ready-to-deploy-hf/jarvis_quantum_llm.npz

# Reinstall numpy
pip install --upgrade numpy

# Try again
python3 numpy_to_gguf.py
```

### Slow generation
Try Q4_0 quantization (see above) for faster inference.

### Poor quality responses
1. Use higher quantization (F16 or F32)
2. Generate more training data
3. Retrain the model

---

## ğŸ“Š Understanding the Output

When Jarvis generates text, it:
1. Tokenizes your prompt
2. Runs forward pass through quantum transformer
3. Applies attention with superposition/entanglement
4. Generates tokens using top-k sampling
5. Returns coherent response

The quantum features (superposition, entanglement, interference) are mathematical analogies that improve the model's ability to understand complex relationships in the data.

---

## ğŸ“ Learn More

- **Full README**: See `README.md` for complete documentation
- **Source Code**: Check `../src/quantum_llm/` for implementation
- **Training**: See parent directory for training scripts
- **Quantum Features**: Read about attention mechanisms in the code

---

## âœ¨ Tips for Best Results

1. **Clear prompts**: "Explain X" works better than vague questions
2. **Scientific topics**: Model trained on science, works best there
3. **Reasonable length**: Keep prompts under 100 words
4. **Context**: Provide context for better responses
5. **Experiment**: Try different temperatures (0.7-1.0)

---

## ğŸ‰ You're Ready!

Your Jarvis Quantum LLM is set up and ready to use. Enjoy your from-scratch, quantum-inspired AI assistant!

**Remember**: This is a real, trained-from-scratch model. Every parameter was learned through genuine backpropagation. No pre-trained weights, no shortcuts, 100% authentic machine learning! ğŸš€
